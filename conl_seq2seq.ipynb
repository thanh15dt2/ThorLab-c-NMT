{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cộng_đồng Cộng_đồng X N nsubj xxxxxxxxx False False\n",
      "xử_lý xử_lý X V ROOT xxxxx False True\n",
      "ngôn_ngữ ngôn_ngữ X N obj xxxxxxxx False False\n",
      "tự_nhiên tự_nhiên X A compound xxxxxxxx False False\n"
     ]
    }
   ],
   "source": [
    "# Spacy for Vietnamese \n",
    "import spacy\n",
    "nlp = spacy.load('vi_spacy_model')\n",
    "doc = nlp('Cộng đồng xử lý ngôn ngữ tự nhiên')\n",
    "for token in doc:\n",
    "    print(token.text, token.lemma_, token.pos_, token.tag_, token.dep_,\n",
    "            token.shape_, token.is_alpha, token.is_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchtext.datasets import Multi30k\n",
    "from torchtext.data import Field, BucketIterator\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "import spacy\n",
    "import numpy as np\n",
    "\n",
    "import random\n",
    "import math\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1234\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: en_core_web_sm==2.2.0 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.0/en_core_web_sm-2.2.0.tar.gz#egg=en_core_web_sm==2.2.0 in /home/bluesky/anaconda3/lib/python3.8/site-packages (2.2.0)\n",
      "Requirement already satisfied: spacy>=2.2.0 in /home/bluesky/anaconda3/lib/python3.8/site-packages (from en_core_web_sm==2.2.0) (2.2.1)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /home/bluesky/anaconda3/lib/python3.8/site-packages (from spacy>=2.2.0->en_core_web_sm==2.2.0) (1.18.5)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.2.0 in /home/bluesky/anaconda3/lib/python3.8/site-packages (from spacy>=2.2.0->en_core_web_sm==2.2.0) (0.8.0)\n",
      "Requirement already satisfied: thinc<7.2.0,>=7.1.1 in /home/bluesky/anaconda3/lib/python3.8/site-packages (from spacy>=2.2.0->en_core_web_sm==2.2.0) (7.1.1)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/bluesky/anaconda3/lib/python3.8/site-packages (from spacy>=2.2.0->en_core_web_sm==2.2.0) (1.0.4)\n",
      "Requirement already satisfied: srsly<1.1.0,>=0.1.0 in /home/bluesky/anaconda3/lib/python3.8/site-packages (from spacy>=2.2.0->en_core_web_sm==2.2.0) (1.0.4)\n",
      "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /home/bluesky/anaconda3/lib/python3.8/site-packages (from spacy>=2.2.0->en_core_web_sm==2.2.0) (0.4.1)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/bluesky/anaconda3/lib/python3.8/site-packages (from spacy>=2.2.0->en_core_web_sm==2.2.0) (3.0.4)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /home/bluesky/anaconda3/lib/python3.8/site-packages (from spacy>=2.2.0->en_core_web_sm==2.2.0) (2.24.0)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/bluesky/anaconda3/lib/python3.8/site-packages (from spacy>=2.2.0->en_core_web_sm==2.2.0) (2.0.4)\n",
      "Requirement already satisfied: plac<1.0.0,>=0.9.6 in /home/bluesky/anaconda3/lib/python3.8/site-packages (from spacy>=2.2.0->en_core_web_sm==2.2.0) (0.9.6)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.10.0 in /home/bluesky/anaconda3/lib/python3.8/site-packages (from thinc<7.2.0,>=7.1.1->spacy>=2.2.0->en_core_web_sm==2.2.0) (4.47.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/bluesky/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.0->en_core_web_sm==2.2.0) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/bluesky/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.0->en_core_web_sm==2.2.0) (2020.6.20)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /home/bluesky/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.0->en_core_web_sm==2.2.0) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/bluesky/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.0->en_core_web_sm==2.2.0) (1.25.9)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the model via spacy.load('en_core_web_sm')\n",
      "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
      "/home/bluesky/anaconda3/lib/python3.8/site-packages/en_core_web_sm -->\n",
      "/home/bluesky/anaconda3/lib/python3.8/site-packages/spacy/data/en\n",
      "You can now load the model via spacy.load('en')\n"
     ]
    }
   ],
   "source": [
    "spacy_vi = spacy.load('vi_spacy_model')\n",
    "!python3 -m spacy download en\n",
    "spacy_en = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_vi(text):\n",
    "    \"\"\"\n",
    "    Tokenizes German text from a string into a list of strings\n",
    "    \"\"\"\n",
    "    return [tok.text for tok in spacy_vi.tokenizer(text)]\n",
    "\n",
    "def tokenize_en(text):\n",
    "    \"\"\"\n",
    "    Tokenizes English text from a string into a list of strings\n",
    "    \"\"\"\n",
    "    return [tok.text for tok in spacy_en.tokenizer(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "SRC = Field(tokenize = tokenize_en, \n",
    "            init_token = '<sos>', \n",
    "            eos_token = '<eos>', \n",
    "            lower = True, \n",
    "            batch_first = True)\n",
    "TRG = Field(tokenize = tokenize_vi, \n",
    "            init_token = '<sos>', \n",
    "            eos_token = '<eos>', \n",
    "            lower = True, \n",
    "            batch_first = True)\n",
    "\n",
    "\n",
    "\n",
    "# TODO\n",
    "# build function tokenizer\n",
    "# build function load and preprocessing data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bluesky/anaconda3/lib/python3.8/site-packages/torchtext/data/example.py:78: UserWarning: Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.', UserWarning)\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '.data/multi30k/test2016.en'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-c5b62f530978>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m train_data, valid_data, test_data = Multi30k.splits(exts=('.en', '.vn'), \n\u001b[0m\u001b[1;32m      2\u001b[0m                                                     fields=(SRC, TRG))\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torchtext/datasets/translation.py\u001b[0m in \u001b[0;36msplits\u001b[0;34m(cls, exts, fields, root, train, validation, test, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'path'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m         return super(Multi30k, cls).splits(\n\u001b[0m\u001b[1;32m    114\u001b[0m             exts, fields, path, root, train, validation, test, **kwargs)\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torchtext/datasets/translation.py\u001b[0m in \u001b[0;36msplits\u001b[0;34m(cls, exts, fields, path, root, train, validation, test, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m         val_data = None if validation is None else cls(\n\u001b[1;32m     68\u001b[0m             os.path.join(path, validation), exts, fields, **kwargs)\n\u001b[0;32m---> 69\u001b[0;31m         test_data = None if test is None else cls(\n\u001b[0m\u001b[1;32m     70\u001b[0m             os.path.join(path, test), exts, fields, **kwargs)\n\u001b[1;32m     71\u001b[0m         return tuple(d for d in (train_data, val_data, test_data)\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torchtext/datasets/translation.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path, exts, fields, **kwargs)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mexamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msrc_file\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m                 \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrg_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtrg_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0msrc_line\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrg_line\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrg_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '.data/multi30k/test2016.en'"
     ]
    }
   ],
   "source": [
    "train_data, valid_data, test_data = Multi30k.splits(exts=('.en', '.vn'), \n",
    "                                                    fields=(SRC, TRG))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SRC.build_vocab(train_data, min_freq = 2)\n",
    "TRG.build_vocab(train_data, min_freq = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "\n",
    "train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data), \n",
    "     batch_size = BATCH_SIZE,\n",
    "     device = device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
